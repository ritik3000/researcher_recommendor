{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-da7fe5b8ac5f>\", line 1, in <module>\n",
      "    df1=pd.read_json(\"jsons/dblp-ref-0.json\",lines=True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\", line 422, in read_json\n",
      "    result = json_reader.read()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\", line 526, in read\n",
      "    self._combine_lines(data.split('\\n'))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\", line 546, in _get_object_parser\n",
      "    obj = FrameParser(json, **kwargs).parse()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\", line 638, in parse\n",
      "    self._parse_no_numpy()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\json.py\", line 853, in _parse_no_numpy\n",
      "    loads(json, precise_float=self.precise_float), dtype=None)\n",
      "ValueError: Expected object or value\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ValueError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 195, in __getattribute__\n",
      "    return getattr(getmod(), name)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 179, in getmod\n",
      "    x = importobj(modpath, None)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\py\\_vendored_packages\\apipkg.py\", line 69, in importobj\n",
      "    module = __import__(modpath, None, None, ['__doc__'])\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pytest.py\", line 15, in <module>\n",
      "    from _pytest.freeze_support import freeze_includes\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 780, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 832, in get_data\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "df1=pd.read_json(\"jsons/dblp-ref-0.json\",lines=True)\n",
    "df2=pd.read_json(\"jsons/dblp-ref-1.json\",lines=True)\n",
    "df3=pd.read_json(\"jsons/dblp-ref-2.json\",lines=True)\n",
    "df4=pd.read_json(\"jsons/dblp-ref-3.json\",lines=True)\n",
    "frames=[df1,df2,df3,df4]\n",
    "df=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_abstract(old_abstract):\n",
    "    \n",
    "    if 'Background#R##N#' in old_abstract:\n",
    "        lowercase = old_abstract[16:].lower()\n",
    "        punc = lowercase.translate(str.maketrans('','',string.punctuation))\n",
    "        \n",
    "        return(punc.translate(str.maketrans('','','1234567890')))\n",
    "    \n",
    "    lowercase = old_abstract.lower()\n",
    "    punc = lowercase.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    return(punc.translate(str.maketrans('','','1234567890')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(handle_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2548532,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = '\\n'.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the purpose of this study is to develop a learning tool for high school students studying the scientific aspects of information and communication net works more specifically we focus on the basic principles of network proto cols as the aim to develop our learning tool our tool gives students handson experience to help understand the basic principles of network protocols\n",
      "this paper describes the design and implementation of a methodology for the visualisation and hypothetical virtual reconstruction of roman polychrome statuary for research purposes the methodology is intended as an attempt to move beyond visualisations which are simply believable towards a more physically accurate approach accurate representations of polychrome statuary have great potential utility both as a means of illustrating existing interpretations and as a means of testing and revising developing hypotheses the goal of this methodology is to propose a pipeline which incorporates a high degree of physical accuracy whilst also being practically applicable in a conventional archaeological research setting the methodology is designed to allow the accurate visualisation of surviving objects and colourants as well as providing reliable methods for the hypothetical reconstruction of elements which no longer survive the process proposed here is intended to limit the need for specialist recording equipment utilising existing data and those data which can be collected using widely available technology it is at present being implemented as part of the statues in context project at herculaneum and will be demonstrated here using the case study of a small area of the head of a painted female statue discovered at herculaneum in \n",
      "this article applied garch model instead ar or arma model to compare with the standard bp and svm in forecasting of the four international including two asian stock markets indicesthese models were evaluated on five performance metrics or criteria our experimental results showed the superiority of svm and garch models compared to the standard bp in forecasting of the four international stock markets indices\n",
      "recent achievements in natural language processing nlp and psychology invoke the challenges to identify the insight of emotions in the present study we have identified different psychology related theme words while analyzing emotions on the interview data of isear international survey of emotion antecedents and reactions research group primarily we have developed a graphical user interface gui to generate visual graphs for analyzing the impact of emotions with respect to different background behavioral and physiological variables available in the isear dataset we have discussed some of the interesting results as observed from the generated visual graphs on the other hand different text clusters are identified from the interview statements by selecting individual as well as different combinations of the variables such textual clusters are used not only for retrieving the psychological theme words but also to classify the theme words into their respective emotion classes in order to retrieve the psychological theme words from the text clusters we have developed a rule based baseline system considering unigram based keyword spotting technique the system has been evaluated based on a topn ranking strategy where n  or  most frequent theme words overall the system achieves the average fscores of       and  in identifying theme words with respect to joy anger disgust fear guilt sadness and shame emotion classes respectively\n",
      "recently bridges and reich introduced the concept of multisymplectic spectral discretizations for hamiltonian wave equations with periodic boundary conditions  in this paper we show that the id nonlinear schrodinger equation and the d grosspitaevskii equation are multisymplectic and derive multisymplectic spectral discretizations of these systems the effectiveness of the discretizations is numerically tested using initial data for multiphase solutions\n",
      "most applications of the abstract interpretation framework have been foranalyzing functional programs use functions on abstract values to approximate functions thus assuming that functions may be called at all argumentswhen the abstract domain is ﬁnite this approach can easily be generalizedto higher order functional languages as shown for example by  in practicethis leads to combinatorial explosion problems as observed for example instrictness analysis of higher order functional languages\n",
      "three speech training systems for hearingimpaired children were designed and constructed using a minicomputer and a microprocessor the first system displays the lateral shape of the vocal tract for each vowel estimated from the speech sound in this system three storages are prepared one of them can be used to store a reference shape which may be estimated from a teachers voice or a prepared standard shape a child can articulate seeing the reference shape and rearticulate comp\n"
     ]
    }
   ],
   "source": [
    "print(abstracts[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('others/doc2veccorpus.txt','w') as f:\n",
    "    f.write(abstracts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
